# Topics to cover

# Linear Algebra
- [ ] [Determinant as an area](https://www.khanacademy.org/math/precalculus/x9e81a4f98389efdf:matrices/x9e81a4f98389efdf:matrices-as-transformations/v/interpreting-determinants-in-terms-of-area#:~:text=The%20determinant%20of%20a%202X2,would%20be%20under%20the%20transformation.)
- [ ] [Determinant of a product](./math_ML/determinant_of_a_product.ipynb)
  - [Youtube video](https://www.youtube.com/watch?v=eF062w5bQ7A)
- [ ] [Determinants of inverses](https://www.youtube.com/watch?v=kWorj5BBy9k)
- [ ] [Bases in Linear Algebra](https://www.youtube.com/watch?v=zntNi3-ybfQ)
- [ ] [Span in Linear Algebra](https://www.youtube.com/watch?v=k7RM-ot2NWY)
- [ ] [Eigenbases](https://www.youtube.com/watch?v=EJG6gBeVdfw)
- [ ] [Eigenvalues and eigenvectors](https://www.youtube.com/watch?v=PFDu9oVAE-g)

# Calculus

## Derivatives
- [ ] Derivatives and Tangents
- [ ] Slopes, maxima and minima
- [ ] Derivatives and their notation
- [ ] Some common derivatives - Lines
- [ ] Some common Derivatives - Quadratics
- [ ] Some common derivatives - Higher degree polynomials
- [ ] Some common derivatives - Other power functions
- [ ] The inverse function and its derivative
- [ ] Derivative of trigonometric functions
- [ ] Meaning of the Exponential (e)
- [ ] The derivative of e^x
- [ ] The derivative of log(x)
- [ ] Existence of the derivative
- [ ] Properties of the derivative: Multiplication by scalars
- [ ] Properties of the derivative: The sum rule
- [ ] Properties of the derivative: The product rule
- [ ] Properties of the derivative: The chain rule
- [ ] Introduction to optimization
- [ ] Optimization of squared loss - The one powerline problem
- [ ] Optimization of squared loss - The two powerline problem
- [ ] Optimization of squared loss - The three powerline problem
- [ ] Optimization of log-loss - Part 1
- [ ] Optimization of log-loss - Part 2

# Gradient Descent
- [ ] Introduction to Tangent planes
- [ ] Partial derivatives - Part 1
- [ ] Partial derivatives - Part 2
- [ ] Gradients
- [ ] Gradients and maxima/minima
- [ ] Optimization with gradients: An example
- [ ] Optimization using gradients - Analytical method
- [ ] Optimization using Gradient Descent in one variable - Part 1
- [ ] Optimization using Gradient Descent in one variable - Part 2
- [ ] Optimization using Gradient Descent in one variable - Part 3
- [ ] Optimization using Gradient Descent in two variables - Part 1
- [ ] Optimization using Gradient Descent in two variables - Part 2
- [ ] Optimization using Gradient Descent - Least squares
- [ ] Optimization using Gradient Descent - Least squares with multiple observations

# Optimization in Neural Networks and Newton's Method
- [ ] Optimization in Neural Networks and Newton's Method
- [ ] Regression with a perceptron
- [ ] Regression with a perceptron - Loss function
- [ ] Regression with a perceptron - Gradient Descent
- [ ] Classification with Perceptron
- [ ] Classification with Perceptron - The sigmoid function
- [ ] Classification with Perceptron - Gradient Descent
- [ ] Classification with Perceptron - Calculating the derivatives
- [ ] Classification with a Neural Network
- [ ] Classification with a Neural Network - Minimizing log-loss
- [ ] Gradient Descent and Backpropagation
- [ ] Newton's Method
- [ ] Newton's Method: An example
- [ ] The second derivative
- [ ] The Hessian
- [ ] Hessians and concavity
- [ ] Newton's Method for two variables

# Probability and Statistics for ML

<!-- below was generated with chatgpt by providing this prompt: Propose a simplified curriculum to covert Probability and Statistics for Machine Learning in one week assuming 2 to 3 hours of effort per day. -->

Day 1: Probability Basics

- [ ] Introduction to probability theory
- [ ] Random variables and probability distributions
- [ ] Discrete and continuous distributions (Uniform, Bernoulli, Binomial, Poisson)

Day 2: Probability Distributions (continued)

- [ ] Continuous distributions (Normal, Exponential, Beta)
- [ ] Joint, conditional, and marginal probabilities
- [ ] Bayes' theorem and its applications

Day 3: Descriptive Statistics and Data Visualization

- [ ] Measures of central tendency (mean, median, mode)
- [ ] Measures of dispersion (range, variance, standard deviation)
- [ ] Data visualization techniques (histograms, box plots, scatter plots)

Day 4: Inferential Statistics

- [ ] Sampling and sampling distributions
- [ ] Confidence intervals
- [ ] Hypothesis testing (t-test, chi-square test, ANOVA)

Day 5: Regression Analysis

- [ ] Simple linear regression
- [ ] Multiple linear regression
- [ ] Logistic regression

Day 6: Statistical Learning and Model Validation

- Bias-variance tradeoff
- Cross-validation and train-test split
- Model evaluation metrics (accuracy, precision, recall, F1-score, AUC-ROC)

Day 7: Bayesian Methods and Intro to Machine Learning

- Bayesian networks and graphical models
- Na√Øve Bayes classifier


